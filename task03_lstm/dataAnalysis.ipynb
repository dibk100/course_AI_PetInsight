{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21822074",
   "metadata": {},
   "source": [
    "# ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5120f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACTION] JSON íŒŒì¼ ìˆ˜: 829\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = '../data'\n",
    "\n",
    "# 1. action ë””ë ‰í† ë¦¬ ë‚´ json íŒŒì¼ ì´ë¦„ (í™•ìž¥ìž ì œê±°)\n",
    "action_json_names = set()\n",
    "action_path = os.path.join(base_dir, 'action')\n",
    "\n",
    "for cls in os.listdir(action_path):\n",
    "    cls_path = os.path.join(action_path, cls)\n",
    "    if not os.path.isdir(cls_path): continue\n",
    "    for session in os.listdir(cls_path):\n",
    "        session_path = os.path.join(cls_path, session)\n",
    "        if not os.path.isdir(session_path): continue\n",
    "        for fname in os.listdir(session_path):\n",
    "            if fname.endswith('.json'):\n",
    "                json_name = os.path.splitext(fname)[0]\n",
    "                action_json_names.add(json_name)\n",
    "\n",
    "print(f\"[ACTION] JSON íŒŒì¼ ìˆ˜: {len(action_json_names)}\")\n",
    "# ìœ ë‹ˆí¬í•œ ë°ì´í„°(ë™ì˜ìƒ) : 829ê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acf5d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Action ë¼ë²¨ ë¶„í¬ ===\n",
      "ê·¸ë£¨ë°í•˜ëŠ” ë™ìž‘: 187\n",
      "í—ˆë¦¬ë¥¼ ì•„ì¹˜ë¡œ ì„¸ìš°ëŠ” ë™ìž‘: 180\n",
      "ê¼¬ë¦¬ë¥¼ í”ë“œëŠ” ë™ìž‘: 49\n",
      "ì•žë°œì„ ë»—ì–´ íœ˜ì ê±°ë¦¬ëŠ” ë™ìž‘: 48\n",
      "ê±·ê±°ë‚˜ ë‹¬ë¦¬ëŠ” ë™ìž‘: 48\n",
      "ë‚©ìž‘ ì—Žë“œë¦¬ëŠ” ë™ìž‘: 47\n",
      "ë°°ë¥¼ ë³´ì—¬ì£¼ëŠ” ë™ìž‘: 46\n",
      "ì˜†ìœ¼ë¡œ ëˆ•ëŠ” ë™ìž‘: 46\n",
      "ì¢Œìš°ë¡œ ë’¹êµ¬ëŠ” ë™ìž‘: 45\n",
      "ë¨¸ë¦¬ë¥¼ ë“¤ì´ëŒ€ëŠ” ë™ìž‘: 45\n",
      "ì•žë°œë¡œ ê¾¹ê¾¹ ëˆ„ë¥´ëŠ” ë™ìž‘: 44\n",
      "ë°œì„ ìˆ¨ê¸°ê³  ì›…í¬ë¦¬ê³  ì•‰ëŠ” ë™ìž‘: 44\n",
      "\n",
      "=== Emotion ë¼ë²¨ ë¶„í¬ ===\n",
      "íŽ¸ì•ˆ/ì•ˆì •: 586\n",
      "í–‰ë³µ/ì¦ê±°ì›€: 124\n",
      "ê³µê²©ì„±: 51\n",
      "í™”ë‚¨/ë¶ˆì¾Œ: 30\n",
      "ë¶ˆì•ˆ/ìŠ¬í””: 21\n",
      "ê³µí¬: 17\n",
      "\n",
      "=== Situation ë¼ë²¨ ë¶„í¬ ===\n",
      "íœ´ì‹ì‹œê°„, ìžì‹ ë§Œì˜ ê³µê°„ì— ë“¤ì–´ê°”ì„ ë•Œ(ìº”ë„¬, ì†ŒíŒŒ ì¹¨ëŒ€ ë°‘ ë“±): 286\n",
      "ê¸°íƒ€: 209\n",
      "ë¨¹ì„ê²ƒ, ìž¥ë‚œê°ì´ ì•žì— ìžˆì„ ë•Œ: 148\n",
      "íŽ¸ì•ˆížˆ ì“°ë‹¤ë“¬ì–´ ì¤„ ë•Œ: 65\n",
      "ë³´í˜¸ìžê°€ ì§‘ì— ëŒì•„ì™”ì„ ë•Œ: 49\n",
      "ë‚¯ì„  ì¡´ìž¬ë¥¼ ë§Œë‚œ ìƒí™©: 16\n",
      "ë‚¯ì„  ìž¥ì†Œ/ì†Œë¦¬ ìƒí™©: 15\n",
      "ë¹—ì§ˆ/ë°œí†±ê¹ê¸°/ëª©ìš• ë“± ìœ„ìƒê´€ë¦¬ë¥¼ í•  ë•Œ: 9\n",
      "ì‹«ì–´í•˜ëŠ” ë¶€ìœ„ë¥¼ ë§Œì§ˆ ë•Œ: 9\n",
      "ì‚°ì±…ì´ë‚˜ ë…¸ì¦ˆì›Œí¬ ì¤‘: 9\n",
      "ë°¥ê·¸ë¦‡, ìž¥ë‚œê°ê³¼ ê°™ì€ ì†Œìœ ë¬¼ì„ ë§Œì§ˆ ë•Œ: 8\n",
      "ì‚°ì±… ì¤€ë¹„ ë˜ëŠ” ì‚°ì±…ì¤‘ì¼ ë•Œ: 5\n",
      "í˜¼ìž ë‚¨ê²¨ì§„ ìƒí™©: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# label_aliases (ì£¼ì–´ì§„ ëŒ€ë¡œ)\n",
    "label_aliases = {\n",
    "    \"action\": {\n",
    "        \"í—ˆë¦¬ë¥¼ ì•„ì¹˜ë¡œ ì„¸ì›€\": \"í—ˆë¦¬ë¥¼ ì•„ì¹˜ë¡œ ì„¸ìš°ëŠ” ë™ìž‘\",\n",
    "    },\n",
    "    \"situation\": {\n",
    "        \"ë³´í˜¸ìžì™€ ë–¨ì–´ì§ˆ ë•Œ/í˜¼ìž ë‚¨ê²¨ì§€ê±°ë‚˜ ë‚¯ì„ ìž¥ì†Œì— ìžˆì„ ë•Œ\": \"í˜¼ìž ë‚¨ê²¨ì§„ ìƒí™©\",\n",
    "        \"ë‚¯ì„  ì†Œë¦¬ê°€ ë‚˜ê±°ë‚˜ ë‚¯ì„  ì‚¬ëžŒì„ ë´¤ì„ ë•Œ\": \"ë‚¯ì„  ì¡´ìž¬ë¥¼ ë§Œë‚œ ìƒí™©\",\n",
    "        \"ë‹¤ë¥¸ ì‚¬ëžŒì´ë‚˜ ë™ë¬¼ì„ ë§Œë‚¬ì„ ë•Œ\": \"ë‚¯ì„  ì¡´ìž¬ë¥¼ ë§Œë‚œ ìƒí™©\",\n",
    "        \"ë‹¤ë¥¸ ë™ë¬¼ì„ ë³´ê±°ë‚˜ ë‚¯ì„  ì‚¬ëžŒì„ ë§Œë‚  ë•Œ ì‚°ì±… ë‚˜ì™”ì„ ë•Œ\": \"ë‚¯ì„  ì¡´ìž¬ë¥¼ ë§Œë‚œ ìƒí™©\",\n",
    "        \"ë‚¯ì„  ì†Œë¦¬ê°€ ë‚¬ì„ ë•Œ\": \"ë‚¯ì„  ìž¥ì†Œ/ì†Œë¦¬ ìƒí™©\",\n",
    "        \"ë‚¯ì„  ìž¥ì†Œì— ìžˆê±°ë‚˜ ë‚¯ì„  ì†Œë¦¬ê°€ ë‚  ë•Œ\": \"ë‚¯ì„  ìž¥ì†Œ/ì†Œë¦¬ ìƒí™©\",\n",
    "        \"ìž ë“¤ê¸° ì „ì´ë‚˜ ê°™ì´ ëˆ„ì›Œìžˆì„ ë•Œ\": \"íœ´ì‹ì‹œê°„, ìžì‹ ë§Œì˜ ê³µê°„ì— ë“¤ì–´ê°”ì„ ë•Œ(ìº”ë„¬, ì†ŒíŒŒ ì¹¨ëŒ€ ë°‘ ë“±)\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def normalize_label(category, label, alias_map):\n",
    "    \"\"\"alias ë§¤í•‘ëœ ë¼ë²¨ë¡œ ë³€í™˜, ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜\"\"\"\n",
    "    if category in alias_map and label in alias_map[category]:\n",
    "        return alias_map[category][label]\n",
    "    return label\n",
    "\n",
    "base_dir = '../data'\n",
    "action_path = os.path.join(base_dir, 'action')\n",
    "\n",
    "# ë¼ë²¨ë³„ ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "action_counter = Counter()\n",
    "emotion_counter = Counter()\n",
    "situation_counter = Counter()\n",
    "\n",
    "for cls in os.listdir(action_path):\n",
    "    cls_path = os.path.join(action_path, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "    for session in os.listdir(cls_path):\n",
    "        session_path = os.path.join(cls_path, session)\n",
    "        if not os.path.isdir(session_path):\n",
    "            continue\n",
    "        \n",
    "        # JSON íŒŒì¼ ë¡œë“œ (í´ë” ë‚´ 1ê°œ assumed)\n",
    "        json_files = [f for f in os.listdir(session_path) if f.endswith('.json')]\n",
    "        if not json_files:\n",
    "            continue\n",
    "        json_path = os.path.join(session_path, json_files[0])\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        meta = data.get(\"metadata\", {})\n",
    "        inspect = meta.get(\"inspect\", {})\n",
    "        owner = meta.get(\"owner\", {})\n",
    "\n",
    "        raw_action = inspect.get(\"action\") or meta.get(\"action\")\n",
    "        raw_emotion = inspect.get(\"emotion\") or owner.get(\"emotion\")\n",
    "        raw_situation = owner.get(\"situation\")\n",
    "\n",
    "        # ë¼ë²¨ ì •ê·œí™”\n",
    "        action = normalize_label('action', raw_action, label_aliases)\n",
    "        emotion = normalize_label('emotion', raw_emotion, label_aliases)\n",
    "        situation = normalize_label('situation', raw_situation, label_aliases)\n",
    "\n",
    "        # ì¹´ìš´í„° ì—…ë°ì´íŠ¸\n",
    "        if action: action_counter[action] += 1\n",
    "        if emotion: emotion_counter[emotion] += 1\n",
    "        if situation: situation_counter[situation] += 1\n",
    "\n",
    "print(\"=== Action ë¼ë²¨ ë¶„í¬ ===\")\n",
    "for label, count in action_counter.most_common():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(\"\\n=== Emotion ë¼ë²¨ ë¶„í¬ ===\")\n",
    "for label, count in emotion_counter.most_common():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(\"\\n=== Situation ë¼ë²¨ ë¶„í¬ ===\")\n",
    "for label, count in situation_counter.most_common():\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aef73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91939400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62a2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1) alias ë§¤í•‘ ì •ì˜\n",
    "label_aliases = {\n",
    "    \"action\": {\n",
    "        \"í—ˆë¦¬ë¥¼ ì•„ì¹˜ë¡œ ì„¸ì›€\": \"í—ˆë¦¬ë¥¼ ì•„ì¹˜ë¡œ ì„¸ìš°ëŠ” ë™ìž‘\",\n",
    "    },\n",
    "    \"situation\": {\n",
    "        \"ë³´í˜¸ìžì™€ ë–¨ì–´ì§ˆ ë•Œ/í˜¼ìž ë‚¨ê²¨ì§€ê±°ë‚˜ ë‚¯ì„ ìž¥ì†Œì— ìžˆì„ ë•Œ\": \"í˜¼ìž ë‚¨ê²¨ì§„ ìƒí™©\",\n",
    "        \"ë‚¯ì„  ì†Œë¦¬ê°€ ë‚˜ê±°ë‚˜ ë‚¯ì„  ì‚¬ëžŒì„ ë´¤ì„ ë•Œ\": \"ë‚¯ì„  ì¡´ìž¬ë¥¼ ë§Œë‚œ ìƒí™©\",\n",
    "        \"ë‹¤ë¥¸ ì‚¬ëžŒì´ë‚˜ ë™ë¬¼ì„ ë§Œë‚¬ì„ ë•Œ\": \"ë‚¯ì„  ì¡´ìž¬ë¥¼ ë§Œë‚œ ìƒí™©\",\n",
    "        \"ë‹¤ë¥¸ ë™ë¬¼ì„ ë³´ê±°ë‚˜ ë‚¯ì„  ì‚¬ëžŒì„ ë§Œë‚  ë•Œ ì‚°ì±… ë‚˜ì™”ì„ ë•Œ\": \"ë‚¯ì„  ì¡´ìž¬ë¥¼ ë§Œë‚œ ìƒí™©\",\n",
    "        \"ë‚¯ì„  ì†Œë¦¬ê°€ ë‚¬ì„ ë•Œ\": \"ë‚¯ì„  ìž¥ì†Œ/ì†Œë¦¬ ìƒí™©\",\n",
    "        \"ë‚¯ì„  ìž¥ì†Œì— ìžˆê±°ë‚˜ ë‚¯ì„  ì†Œë¦¬ê°€ ë‚  ë•Œ\": \"ë‚¯ì„  ìž¥ì†Œ/ì†Œë¦¬ ìƒí™©\",\n",
    "        \"ìž ë“¤ê¸° ì „ì´ë‚˜ ê°™ì´ ëˆ„ì›Œìžˆì„ ë•Œ\": \"íœ´ì‹ì‹œê°„, ìžì‹ ë§Œì˜ ê³µê°„ì— ë“¤ì–´ê°”ì„ ë•Œ(ìº”ë„¬, ì†ŒíŒŒ ì¹¨ëŒ€ ë°‘ ë“±)\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2) ë¼ë²¨ ì •ê·œí™” í•¨ìˆ˜\n",
    "def normalize_label(category, label, label_aliases):\n",
    "    if category in label_aliases and label in label_aliases[category]:\n",
    "        return label_aliases[category][label]\n",
    "    return label\n",
    "\n",
    "# 3) configë¡œë¶€í„° ë¼ë²¨ ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜\n",
    "def get_label_maps_from_config(config, label_aliases=None):\n",
    "    label_aliases = label_aliases or {}\n",
    "\n",
    "    label_maps = {}\n",
    "    for category in ['action', 'emotion', 'situation']:\n",
    "        raw_labels = config['label_names'][category]\n",
    "        label_maps[category] = {label: i for i, label in enumerate(raw_labels)}\n",
    "\n",
    "        # alias ë§¤í•‘ë„ ì¸ë±ìŠ¤ì— í¬í•¨\n",
    "        for alias, original in label_aliases.get(category, {}).items():\n",
    "            if original not in label_maps[category]:\n",
    "                raise ValueError(f\"Original label '{original}' not found in {category} labels.\")\n",
    "            label_maps[category][alias] = label_maps[category][original]\n",
    "\n",
    "    return label_maps\n",
    "\n",
    "# 4) Dataset í´ëž˜ìŠ¤\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_dirs, label_encoder, label_aliases=None,\n",
    "                 transform=None):\n",
    "        self.video_dirs = video_dirs\n",
    "        self.label_encoder = label_encoder\n",
    "        self.label_aliases = label_aliases or {}\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_dirs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_dirs[idx]\n",
    "\n",
    "        # JSON íŒŒì¼ ë¡œë“œ\n",
    "        json_files = [f for f in os.listdir(video_path) if f.endswith(\".json\")]\n",
    "        if not json_files:\n",
    "            raise FileNotFoundError(f\"No JSON file found in {video_path}\")\n",
    "        with open(os.path.join(video_path, json_files[0]), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        meta = data.get(\"metadata\", {})\n",
    "        inspect = meta.get(\"inspect\", {})\n",
    "        owner = meta.get(\"owner\", {})\n",
    "\n",
    "        # ì›ë³¸ ë¼ë²¨ ì¶”ì¶œ\n",
    "        raw_action = inspect.get(\"action\") or meta.get(\"action\")\n",
    "        raw_emotion = inspect.get(\"emotion\") or owner.get(\"emotion\")\n",
    "        raw_situation = owner.get(\"situation\")\n",
    "\n",
    "        if raw_action is None or raw_emotion is None or raw_situation is None:\n",
    "            raise ValueError(f\"Missing label in metadata for {video_path}\")\n",
    "\n",
    "        # ë¼ë²¨ ì •ê·œí™”\n",
    "        norm_action = normalize_label('action', raw_action, self.label_aliases)\n",
    "        norm_emotion = normalize_label('emotion', raw_emotion, self.label_aliases)\n",
    "        norm_situation = normalize_label('situation', raw_situation, self.label_aliases)\n",
    "\n",
    "        # ì¸ë±ìŠ¤ ë³€í™˜\n",
    "        action_idx = self.label_encoder['action'][norm_action]\n",
    "        emotion_idx = self.label_encoder['emotion'][norm_emotion]\n",
    "        situation_idx = self.label_encoder['situation'][norm_situation]\n",
    "\n",
    "        # í”„ë ˆìž„ ì´ë¯¸ì§€ ì „ì²´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        frame_files = sorted([f for f in os.listdir(video_path) if f.endswith(\".jpg\")])\n",
    "        frames = []\n",
    "        for fname in frame_files:\n",
    "            img_path = os.path.join(video_path, fname)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = self.transform(img)\n",
    "            frames.append(img)\n",
    "\n",
    "        if not frames:\n",
    "            raise ValueError(f\"No image frames found in {video_path}\")\n",
    "\n",
    "        frames_tensor = torch.stack(frames)  # (T, C, H, W)\n",
    "        labels_tensor = torch.tensor([action_idx, emotion_idx, situation_idx], dtype=torch.long)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "    \n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    ìƒ˜í”Œë§ˆë‹¤ í”„ë ˆìž„ ìˆ˜ê°€ ë‹¬ë¼ì§..\n",
    "    \"\"\"\n",
    "    videos, labels = zip(*batch)\n",
    "    return list(videos), torch.stack(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ba7d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 829 video folders with JSON\n",
      "# Samples: 4\n",
      "1st sample shape: torch.Size([89, 3, 224, 224])\n",
      "Labels shape: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"./configs/base.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "label_encoder = get_label_maps_from_config(config, label_aliases)\n",
    "\n",
    "import os\n",
    "# 1. JSON íŒŒì¼ì´ ìžˆëŠ” í´ë”ë§Œ ëª¨ìœ¼ê¸°\n",
    "base_path = \"../data/action\"\n",
    "video_dirs_with_json = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            video_dirs_with_json.append(root)\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(video_dirs_with_json)} video folders with JSON\")\n",
    "\n",
    "# 2. Dataset ìƒì„±\n",
    "dataset = VideoDataset(video_dirs_with_json, label_encoder, label_aliases)\n",
    "\n",
    "# 3. DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=custom_collate)\n",
    "\n",
    "for videos, labels in dataloader:\n",
    "    print(f\"# Samples: {len(videos)}\")\n",
    "    print(f\"1st sample shape: {videos[0].shape}\")  # e.g., (T, C, H, W)\n",
    "    print(f\"Labels shape: {labels.shape}\")         # (B, 3)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41dbe3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 11\n",
      "6 1 11\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 10\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 14\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 8\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 14\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 5 14\n",
      "6 1 10\n",
      "6 1 14\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 0 14\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 0 14\n",
      "6 1 10\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 9\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 4\n",
      "6 1 12\n",
      "6 1 11\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m         situation_counter[situation] += \u001b[32m1\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m: action_counter,\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m: emotion_counter,\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msituation\u001b[39m\u001b[33m\"\u001b[39m: situation_counter\n\u001b[32m     20\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m distribution = \u001b[43mcompute_label_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcompute_label_distribution\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m      6\u001b[39m situation_counter = Counter()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     _, label_tensor = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m     action, emotion, situation = label_tensor.tolist()\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(action, emotion, situation)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mVideoDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m frame_files:\n\u001b[32m     98\u001b[39m     img_path = os.path.join(video_path, fname)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     img = \u001b[38;5;28mself\u001b[39m.transform(img)\n\u001b[32m    101\u001b[39m     frames.append(img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/PIL/Image.py:984\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBGR;15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;24\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    982\u001b[39m     deprecate(mode, \u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/PIL/ImageFile.py:300\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    299\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m n, err_code = \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def compute_label_distribution(dataset):\n",
    "    action_counter = Counter()\n",
    "    emotion_counter = Counter()\n",
    "    situation_counter = Counter()\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        _, label_tensor = dataset[i]\n",
    "        action, emotion, situation = label_tensor.tolist()\n",
    "        print(action, emotion, situation)\n",
    "        action_counter[action] += 1\n",
    "        emotion_counter[emotion] += 1\n",
    "        situation_counter[situation] += 1\n",
    "\n",
    "    return {\n",
    "        \"action\": action_counter,\n",
    "        \"emotion\": emotion_counter,\n",
    "        \"situation\": situation_counter\n",
    "    }\n",
    "\n",
    "distribution = compute_label_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c86bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, counter in distribution.items():\n",
    "    print(f\"\\nðŸ“Š {category.upper()} label distribution:\")\n",
    "    for label_idx, count in sorted(counter.items()):\n",
    "        label_name = list(label_encoder[category].keys())[list(label_encoder[category].values()).index(label_idx)]\n",
    "        print(f\"  [{label_idx:2}] {label_name:<40} : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96511aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0c753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8e210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3561037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def extract_situation_label(video_path, label_encoder, label_aliases):\n",
    "    \"\"\"situation ë¼ë²¨ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    json_files = [f for f in os.listdir(video_path) if f.endswith(\".json\")]\n",
    "    if not json_files:\n",
    "        return None\n",
    "\n",
    "    with open(os.path.join(video_path, json_files[0]), \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    meta = data.get(\"metadata\", {})\n",
    "    owner = meta.get(\"owner\", {})\n",
    "    raw_situation = owner.get(\"situation\")\n",
    "\n",
    "    if raw_situation is None:\n",
    "        return None\n",
    "\n",
    "    def normalize(category, label):\n",
    "        if category in label_aliases and label in label_aliases[category]:\n",
    "            return label_aliases[category][label]\n",
    "        return label\n",
    "\n",
    "    try:\n",
    "        situation = label_encoder[\"situation\"][normalize(\"situation\", raw_situation)]\n",
    "        return situation\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3fa37f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m         y.append(sit)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# stratified split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m train_dirs, val_dirs = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[SPLIT DONE] Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dirs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m / Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_dirs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2940\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2936\u001b[39m         CVClass = ShuffleSplit\n\u001b[32m   2938\u001b[39m     cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state)\n\u001b[32m-> \u001b[39m\u001b[32m2940\u001b[39m     train, test = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2942\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m   2944\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2945\u001b[39m     chain.from_iterable(\n\u001b[32m   2946\u001b[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2947\u001b[39m     )\n\u001b[32m   2948\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/model_selection/_split.py:1927\u001b[39m, in \u001b[36mBaseShuffleSplit.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   1897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m   1898\u001b[39m \n\u001b[32m   1899\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1924\u001b[39m \u001b[33;03mto an integer.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1926\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2342\u001b[39m, in \u001b[36mStratifiedShuffleSplit._iter_indices\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   2340\u001b[39m class_counts = np.bincount(y_indices)\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.min(class_counts) < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m member, which is too few. The minimum\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of groups for any class cannot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be less than 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2347\u001b[39m     )\n\u001b[32m   2349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train < n_classes:\n\u001b[32m   2350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2351\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m should be greater or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (n_train, n_classes)\n\u001b[32m   2353\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# ëª¨ë“  ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘\n",
    "video_dirs = glob.glob(\"../data/action/**/*/\", recursive=True)\n",
    "video_dirs = [d for d in video_dirs if os.path.isdir(d)]\n",
    "\n",
    "# situation ì¸ë±ìŠ¤ ìˆ˜ì§‘\n",
    "X, y = [], []\n",
    "\n",
    "for d in video_dirs:\n",
    "    sit = extract_situation_label(d, label_encoder, label_aliases)\n",
    "    if sit is not None:\n",
    "        X.append(d)\n",
    "        y.append(sit)\n",
    "\n",
    "# stratified split\n",
    "train_dirs, val_dirs = train_test_split(\n",
    "    X, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"[SPLIT DONE] Train: {len(train_dirs)} / Val: {len(val_dirs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train action dist: Counter({6: 150, 0: 144, 11: 39, 12: 38, 1: 38, 5: 38, 10: 37, 7: 37, 4: 36, 2: 36, 3: 35, 9: 35})\n",
      "Val action dist:   Counter({6: 37, 0: 36, 11: 10, 1: 10, 12: 10, 5: 9, 9: 9, 4: 9, 2: 9, 10: 9, 3: 9, 7: 9})\n"
     ]
    }
   ],
   "source": [
    "print(\"Train ì¡°í•© ë¶„í¬:\")\n",
    "print(Counter([extract_label_triplet(d, label_encoder, label_aliases) for d in train_dirs]))\n",
    "\n",
    "print(\"Val ì¡°í•© ë¶„í¬:\")\n",
    "print(Counter([extract_label_triplet(d, label_encoder, label_aliases) for d in val_dirs]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
