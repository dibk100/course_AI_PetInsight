{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21822074",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5120f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACTION] JSON 파일 수: 829\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = '../data'\n",
    "\n",
    "# 1. action 디렉토리 내 json 파일 이름 (확장자 제거)\n",
    "action_json_names = set()\n",
    "action_path = os.path.join(base_dir, 'action')\n",
    "\n",
    "for cls in os.listdir(action_path):\n",
    "    cls_path = os.path.join(action_path, cls)\n",
    "    if not os.path.isdir(cls_path): continue\n",
    "    for session in os.listdir(cls_path):\n",
    "        session_path = os.path.join(cls_path, session)\n",
    "        if not os.path.isdir(session_path): continue\n",
    "        for fname in os.listdir(session_path):\n",
    "            if fname.endswith('.json'):\n",
    "                json_name = os.path.splitext(fname)[0]\n",
    "                action_json_names.add(json_name)\n",
    "\n",
    "print(f\"[ACTION] JSON 파일 수: {len(action_json_names)}\")\n",
    "# 유니크한 데이터(동영상) : 829개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acf5d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Action 라벨 분포 ===\n",
      "그루밍하는 동작: 187\n",
      "허리를 아치로 세우는 동작: 180\n",
      "꼬리를 흔드는 동작: 49\n",
      "앞발을 뻗어 휘적거리는 동작: 48\n",
      "걷거나 달리는 동작: 48\n",
      "납작 엎드리는 동작: 47\n",
      "배를 보여주는 동작: 46\n",
      "옆으로 눕는 동작: 46\n",
      "좌우로 뒹구는 동작: 45\n",
      "머리를 들이대는 동작: 45\n",
      "앞발로 꾹꾹 누르는 동작: 44\n",
      "발을 숨기고 웅크리고 앉는 동작: 44\n",
      "\n",
      "=== Emotion 라벨 분포 ===\n",
      "편안/안정: 586\n",
      "행복/즐거움: 124\n",
      "공격성: 51\n",
      "화남/불쾌: 30\n",
      "불안/슬픔: 21\n",
      "공포: 17\n",
      "\n",
      "=== Situation 라벨 분포 ===\n",
      "휴식시간, 자신만의 공간에 들어갔을 때(캔넬, 소파 침대 밑 등): 286\n",
      "기타: 209\n",
      "먹을것, 장난감이 앞에 있을 때: 148\n",
      "편안히 쓰다듬어 줄 때: 65\n",
      "보호자가 집에 돌아왔을 때: 49\n",
      "낯선 존재를 만난 상황: 16\n",
      "낯선 장소/소리 상황: 15\n",
      "빗질/발톱깍기/목욕 등 위생관리를 할 때: 9\n",
      "싫어하는 부위를 만질 때: 9\n",
      "산책이나 노즈워크 중: 9\n",
      "밥그릇, 장난감과 같은 소유물을 만질 때: 8\n",
      "산책 준비 또는 산책중일 때: 5\n",
      "혼자 남겨진 상황: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# label_aliases (주어진 대로)\n",
    "label_aliases = {\n",
    "    \"action\": {\n",
    "        \"허리를 아치로 세움\": \"허리를 아치로 세우는 동작\",\n",
    "    },\n",
    "    \"situation\": {\n",
    "        \"보호자와 떨어질 때/혼자 남겨지거나 낯선장소에 있을 때\": \"혼자 남겨진 상황\",\n",
    "        \"낯선 소리가 나거나 낯선 사람을 봤을 때\": \"낯선 존재를 만난 상황\",\n",
    "        \"다른 사람이나 동물을 만났을 때\": \"낯선 존재를 만난 상황\",\n",
    "        \"다른 동물을 보거나 낯선 사람을 만날 때 산책 나왔을 때\": \"낯선 존재를 만난 상황\",\n",
    "        \"낯선 소리가 났을 때\": \"낯선 장소/소리 상황\",\n",
    "        \"낯선 장소에 있거나 낯선 소리가 날 때\": \"낯선 장소/소리 상황\",\n",
    "        \"잠들기 전이나 같이 누워있을 때\": \"휴식시간, 자신만의 공간에 들어갔을 때(캔넬, 소파 침대 밑 등)\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def normalize_label(category, label, alias_map):\n",
    "    \"\"\"alias 매핑된 라벨로 변환, 없으면 원본 그대로 반환\"\"\"\n",
    "    if category in alias_map and label in alias_map[category]:\n",
    "        return alias_map[category][label]\n",
    "    return label\n",
    "\n",
    "base_dir = '../data'\n",
    "action_path = os.path.join(base_dir, 'action')\n",
    "\n",
    "# 라벨별 카운터 초기화\n",
    "action_counter = Counter()\n",
    "emotion_counter = Counter()\n",
    "situation_counter = Counter()\n",
    "\n",
    "for cls in os.listdir(action_path):\n",
    "    cls_path = os.path.join(action_path, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "    for session in os.listdir(cls_path):\n",
    "        session_path = os.path.join(cls_path, session)\n",
    "        if not os.path.isdir(session_path):\n",
    "            continue\n",
    "        \n",
    "        # JSON 파일 로드 (폴더 내 1개 assumed)\n",
    "        json_files = [f for f in os.listdir(session_path) if f.endswith('.json')]\n",
    "        if not json_files:\n",
    "            continue\n",
    "        json_path = os.path.join(session_path, json_files[0])\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        meta = data.get(\"metadata\", {})\n",
    "        inspect = meta.get(\"inspect\", {})\n",
    "        owner = meta.get(\"owner\", {})\n",
    "\n",
    "        raw_action = inspect.get(\"action\") or meta.get(\"action\")\n",
    "        raw_emotion = inspect.get(\"emotion\") or owner.get(\"emotion\")\n",
    "        raw_situation = owner.get(\"situation\")\n",
    "\n",
    "        # 라벨 정규화\n",
    "        action = normalize_label('action', raw_action, label_aliases)\n",
    "        emotion = normalize_label('emotion', raw_emotion, label_aliases)\n",
    "        situation = normalize_label('situation', raw_situation, label_aliases)\n",
    "\n",
    "        # 카운터 업데이트\n",
    "        if action: action_counter[action] += 1\n",
    "        if emotion: emotion_counter[emotion] += 1\n",
    "        if situation: situation_counter[situation] += 1\n",
    "\n",
    "print(\"=== Action 라벨 분포 ===\")\n",
    "for label, count in action_counter.most_common():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(\"\\n=== Emotion 라벨 분포 ===\")\n",
    "for label, count in emotion_counter.most_common():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(\"\\n=== Situation 라벨 분포 ===\")\n",
    "for label, count in situation_counter.most_common():\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aef73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91939400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62a2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1) alias 매핑 정의\n",
    "label_aliases = {\n",
    "    \"action\": {\n",
    "        \"허리를 아치로 세움\": \"허리를 아치로 세우는 동작\",\n",
    "    },\n",
    "    \"situation\": {\n",
    "        \"보호자와 떨어질 때/혼자 남겨지거나 낯선장소에 있을 때\": \"혼자 남겨진 상황\",\n",
    "        \"낯선 소리가 나거나 낯선 사람을 봤을 때\": \"낯선 존재를 만난 상황\",\n",
    "        \"다른 사람이나 동물을 만났을 때\": \"낯선 존재를 만난 상황\",\n",
    "        \"다른 동물을 보거나 낯선 사람을 만날 때 산책 나왔을 때\": \"낯선 존재를 만난 상황\",\n",
    "        \"낯선 소리가 났을 때\": \"낯선 장소/소리 상황\",\n",
    "        \"낯선 장소에 있거나 낯선 소리가 날 때\": \"낯선 장소/소리 상황\",\n",
    "        \"잠들기 전이나 같이 누워있을 때\": \"휴식시간, 자신만의 공간에 들어갔을 때(캔넬, 소파 침대 밑 등)\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2) 라벨 정규화 함수\n",
    "def normalize_label(category, label, label_aliases):\n",
    "    if category in label_aliases and label in label_aliases[category]:\n",
    "        return label_aliases[category][label]\n",
    "    return label\n",
    "\n",
    "# 3) config로부터 라벨 인덱스 생성 함수\n",
    "def get_label_maps_from_config(config, label_aliases=None):\n",
    "    label_aliases = label_aliases or {}\n",
    "\n",
    "    label_maps = {}\n",
    "    for category in ['action', 'emotion', 'situation']:\n",
    "        raw_labels = config['label_names'][category]\n",
    "        label_maps[category] = {label: i for i, label in enumerate(raw_labels)}\n",
    "\n",
    "        # alias 매핑도 인덱스에 포함\n",
    "        for alias, original in label_aliases.get(category, {}).items():\n",
    "            if original not in label_maps[category]:\n",
    "                raise ValueError(f\"Original label '{original}' not found in {category} labels.\")\n",
    "            label_maps[category][alias] = label_maps[category][original]\n",
    "\n",
    "    return label_maps\n",
    "\n",
    "# 4) Dataset 클래스\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, video_dirs, label_encoder, label_aliases=None,\n",
    "                 transform=None):\n",
    "        self.video_dirs = video_dirs\n",
    "        self.label_encoder = label_encoder\n",
    "        self.label_aliases = label_aliases or {}\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_dirs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_dirs[idx]\n",
    "\n",
    "        # JSON 파일 로드\n",
    "        json_files = [f for f in os.listdir(video_path) if f.endswith(\".json\")]\n",
    "        if not json_files:\n",
    "            raise FileNotFoundError(f\"No JSON file found in {video_path}\")\n",
    "        with open(os.path.join(video_path, json_files[0]), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        meta = data.get(\"metadata\", {})\n",
    "        inspect = meta.get(\"inspect\", {})\n",
    "        owner = meta.get(\"owner\", {})\n",
    "\n",
    "        # 원본 라벨 추출\n",
    "        raw_action = inspect.get(\"action\") or meta.get(\"action\")\n",
    "        raw_emotion = inspect.get(\"emotion\") or owner.get(\"emotion\")\n",
    "        raw_situation = owner.get(\"situation\")\n",
    "\n",
    "        if raw_action is None or raw_emotion is None or raw_situation is None:\n",
    "            raise ValueError(f\"Missing label in metadata for {video_path}\")\n",
    "\n",
    "        # 라벨 정규화\n",
    "        norm_action = normalize_label('action', raw_action, self.label_aliases)\n",
    "        norm_emotion = normalize_label('emotion', raw_emotion, self.label_aliases)\n",
    "        norm_situation = normalize_label('situation', raw_situation, self.label_aliases)\n",
    "\n",
    "        # 인덱스 변환\n",
    "        action_idx = self.label_encoder['action'][norm_action]\n",
    "        emotion_idx = self.label_encoder['emotion'][norm_emotion]\n",
    "        situation_idx = self.label_encoder['situation'][norm_situation]\n",
    "\n",
    "        # 프레임 이미지 전체 불러오기\n",
    "        frame_files = sorted([f for f in os.listdir(video_path) if f.endswith(\".jpg\")])\n",
    "        frames = []\n",
    "        for fname in frame_files:\n",
    "            img_path = os.path.join(video_path, fname)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = self.transform(img)\n",
    "            frames.append(img)\n",
    "\n",
    "        if not frames:\n",
    "            raise ValueError(f\"No image frames found in {video_path}\")\n",
    "\n",
    "        frames_tensor = torch.stack(frames)  # (T, C, H, W)\n",
    "        labels_tensor = torch.tensor([action_idx, emotion_idx, situation_idx], dtype=torch.long)\n",
    "\n",
    "        return frames_tensor, labels_tensor\n",
    "    \n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    샘플마다 프레임 수가 달라짐..\n",
    "    \"\"\"\n",
    "    videos, labels = zip(*batch)\n",
    "    return list(videos), torch.stack(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ba7d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 829 video folders with JSON\n",
      "# Samples: 4\n",
      "1st sample shape: torch.Size([89, 3, 224, 224])\n",
      "Labels shape: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"./configs/base.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "label_encoder = get_label_maps_from_config(config, label_aliases)\n",
    "\n",
    "import os\n",
    "# 1. JSON 파일이 있는 폴더만 모으기\n",
    "base_path = \"../data/action\"\n",
    "video_dirs_with_json = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            video_dirs_with_json.append(root)\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(video_dirs_with_json)} video folders with JSON\")\n",
    "\n",
    "# 2. Dataset 생성\n",
    "dataset = VideoDataset(video_dirs_with_json, label_encoder, label_aliases)\n",
    "\n",
    "# 3. DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=custom_collate)\n",
    "\n",
    "for videos, labels in dataloader:\n",
    "    print(f\"# Samples: {len(videos)}\")\n",
    "    print(f\"1st sample shape: {videos[0].shape}\")  # e.g., (T, C, H, W)\n",
    "    print(f\"Labels shape: {labels.shape}\")         # (B, 3)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41dbe3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 11\n",
      "6 1 11\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 10\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 14\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 8\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 14\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 5 14\n",
      "6 1 10\n",
      "6 1 14\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 0 14\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 0 14\n",
      "6 1 10\n",
      "6 1 3\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 9\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 4\n",
      "6 1 12\n",
      "6 1 11\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 12\n",
      "6 1 3\n",
      "6 1 12\n",
      "6 1 10\n",
      "6 1 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m         situation_counter[situation] += \u001b[32m1\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m: action_counter,\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m: emotion_counter,\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msituation\u001b[39m\u001b[33m\"\u001b[39m: situation_counter\n\u001b[32m     20\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m distribution = \u001b[43mcompute_label_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcompute_label_distribution\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m      6\u001b[39m situation_counter = Counter()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     _, label_tensor = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m     action, emotion, situation = label_tensor.tolist()\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(action, emotion, situation)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mVideoDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m frame_files:\n\u001b[32m     98\u001b[39m     img_path = os.path.join(video_path, fname)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     img = \u001b[38;5;28mself\u001b[39m.transform(img)\n\u001b[32m    101\u001b[39m     frames.append(img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/PIL/Image.py:984\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBGR;15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;24\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    982\u001b[39m     deprecate(mode, \u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/PIL/ImageFile.py:300\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    299\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m n, err_code = \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def compute_label_distribution(dataset):\n",
    "    action_counter = Counter()\n",
    "    emotion_counter = Counter()\n",
    "    situation_counter = Counter()\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        _, label_tensor = dataset[i]\n",
    "        action, emotion, situation = label_tensor.tolist()\n",
    "        print(action, emotion, situation)\n",
    "        action_counter[action] += 1\n",
    "        emotion_counter[emotion] += 1\n",
    "        situation_counter[situation] += 1\n",
    "\n",
    "    return {\n",
    "        \"action\": action_counter,\n",
    "        \"emotion\": emotion_counter,\n",
    "        \"situation\": situation_counter\n",
    "    }\n",
    "\n",
    "distribution = compute_label_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c86bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, counter in distribution.items():\n",
    "    print(f\"\\n📊 {category.upper()} label distribution:\")\n",
    "    for label_idx, count in sorted(counter.items()):\n",
    "        label_name = list(label_encoder[category].keys())[list(label_encoder[category].values()).index(label_idx)]\n",
    "        print(f\"  [{label_idx:2}] {label_name:<40} : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96511aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0c753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8e210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3561037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def extract_situation_label(video_path, label_encoder, label_aliases):\n",
    "    \"\"\"situation 라벨 인덱스를 추출하는 함수\"\"\"\n",
    "    json_files = [f for f in os.listdir(video_path) if f.endswith(\".json\")]\n",
    "    if not json_files:\n",
    "        return None\n",
    "\n",
    "    with open(os.path.join(video_path, json_files[0]), \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    meta = data.get(\"metadata\", {})\n",
    "    owner = meta.get(\"owner\", {})\n",
    "    raw_situation = owner.get(\"situation\")\n",
    "\n",
    "    if raw_situation is None:\n",
    "        return None\n",
    "\n",
    "    def normalize(category, label):\n",
    "        if category in label_aliases and label in label_aliases[category]:\n",
    "            return label_aliases[category][label]\n",
    "        return label\n",
    "\n",
    "    try:\n",
    "        situation = label_encoder[\"situation\"][normalize(\"situation\", raw_situation)]\n",
    "        return situation\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3fa37f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m         y.append(sit)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# stratified split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m train_dirs, val_dirs = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[SPLIT DONE] Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_dirs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m / Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_dirs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2940\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2936\u001b[39m         CVClass = ShuffleSplit\n\u001b[32m   2938\u001b[39m     cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state)\n\u001b[32m-> \u001b[39m\u001b[32m2940\u001b[39m     train, test = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2942\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m   2944\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2945\u001b[39m     chain.from_iterable(\n\u001b[32m   2946\u001b[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2947\u001b[39m     )\n\u001b[32m   2948\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/model_selection/_split.py:1927\u001b[39m, in \u001b[36mBaseShuffleSplit.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   1897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m   1898\u001b[39m \n\u001b[32m   1899\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1924\u001b[39m \u001b[33;03mto an integer.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1926\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sketch/anaconda3/envs/dibk311/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2342\u001b[39m, in \u001b[36mStratifiedShuffleSplit._iter_indices\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   2340\u001b[39m class_counts = np.bincount(y_indices)\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.min(class_counts) < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m member, which is too few. The minimum\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of groups for any class cannot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be less than 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2347\u001b[39m     )\n\u001b[32m   2349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train < n_classes:\n\u001b[32m   2350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2351\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m should be greater or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (n_train, n_classes)\n\u001b[32m   2353\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# 모든 비디오 디렉토리 수집\n",
    "video_dirs = glob.glob(\"../data/action/**/*/\", recursive=True)\n",
    "video_dirs = [d for d in video_dirs if os.path.isdir(d)]\n",
    "\n",
    "# situation 인덱스 수집\n",
    "X, y = [], []\n",
    "\n",
    "for d in video_dirs:\n",
    "    sit = extract_situation_label(d, label_encoder, label_aliases)\n",
    "    if sit is not None:\n",
    "        X.append(d)\n",
    "        y.append(sit)\n",
    "\n",
    "# stratified split\n",
    "train_dirs, val_dirs = train_test_split(\n",
    "    X, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"[SPLIT DONE] Train: {len(train_dirs)} / Val: {len(val_dirs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train action dist: Counter({6: 150, 0: 144, 11: 39, 12: 38, 1: 38, 5: 38, 10: 37, 7: 37, 4: 36, 2: 36, 3: 35, 9: 35})\n",
      "Val action dist:   Counter({6: 37, 0: 36, 11: 10, 1: 10, 12: 10, 5: 9, 9: 9, 4: 9, 2: 9, 10: 9, 3: 9, 7: 9})\n"
     ]
    }
   ],
   "source": [
    "print(\"Train 조합 분포:\")\n",
    "print(Counter([extract_label_triplet(d, label_encoder, label_aliases) for d in train_dirs]))\n",
    "\n",
    "print(\"Val 조합 분포:\")\n",
    "print(Counter([extract_label_triplet(d, label_encoder, label_aliases) for d in val_dirs]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dibk311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
