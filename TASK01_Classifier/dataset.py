import os
import json
from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from torch.utils.data import DataLoader, random_split
from collections import Counter

class LabelEncoder:
    def __init__(self):
        class_names = ['í–‰ë³µ/ì¦ê±°ì›€', 'í¸ì•ˆ/ì•ˆì •', 'ë¶ˆì•ˆ/ìŠ¬í””', 'í™”ë‚¨/ë¶ˆì¾Œ', 'ê³µí¬', 'ê³µê²©ì„±']
        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(class_names)}
        self.idx_to_class = {idx: cls_name for cls_name, idx in self.class_to_idx.items()}

    def encode(self, class_name):
        return self.class_to_idx[class_name]

    def decode(self, index):
        return self.idx_to_class[index]
    
class CatBehaviorDataset(Dataset):
    def __init__(self, json_dir, img_root_dir, transform=None, task='action',describe = False):
        """
        Args:
            json_dir (str): JSON íŒŒì¼ë“¤ì´ ìˆëŠ” CAT_labeled ë””ë ‰í† ë¦¬
            img_root_dir (str): ì´ë¯¸ì§€ê°€ ìˆëŠ” CAT_raw ë””ë ‰í† ë¦¬
            transform (callable, optional): ì´ë¯¸ì§€ì— ì ìš©í•  torchvision transform
            task (str): 'action' ë˜ëŠ” 'emotion' ì¤‘ í•˜ë‚˜
        """
        assert task in ['action', 'emotion'], "taskëŠ” 'action' ë˜ëŠ” 'emotion' ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
        self.json_dir = json_dir
        self.img_root_dir = img_root_dir
        self.transform = transform
        self.task = task
        self.samples = []  # # (image_path, label_str) ë¦¬ìŠ¤íŠ¸
        self.describe = describe        # íŒŒì¼ ìƒíƒœ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ True
        self.label_encoder = LabelEncoder()     # ë¼ë²¨ ì¸ì½”ë” ì¶”ê°€
        self.label_counter = Counter()          # ë¼ë²¨ í†µê³„
        
        self._load_annotations()

    def _load_annotations(self):
        total_video = 0
        total_image = 0
        missing_file = 0
        pass_file = 0
        skip_file = 0
        
        for json_file in os.listdir(self.json_dir):
            total_video += 1
            if not json_file.endswith('.json'):
                print("[Pass] json file : ",json_file)
                pass_file +=1
                continue

            json_path = os.path.join(self.json_dir, json_file)
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            video_path = data.get('file_video')
            if not video_path:
                print("[Pass] file_video : ",json_file)
                pass_file +=1
                continue
            
            video_file = os.path.basename(video_path)  # cat-armstretch-011278.mp4
            video_name = os.path.splitext(video_file)[0]  # cat-armstretch-011278
            parent_dir = os.path.dirname(video_path)     # 20210105
            full_video_folder = f"{parent_dir}_{video_file}"  # 20210105_cat-armstretch-011278.mp4
            
            # issue : íŒŒì¼ëª… ì˜¤ë¥˜ ë•Œë¬¸ì— í™•ì¸í•˜ëŠ” ì‘ì—… ì¶”ê°€ : ì—¬ëŸ¬ í›„ë³´ ê²½ë¡œ ìƒì„±
            candidate_folders = [
                os.path.join(self.img_root_dir, full_video_folder),  # 20210105_cat-armstretch-011278.mp4
                os.path.join(self.img_root_dir, video_name),         # cat-armstretch-011278
            ]
            
            found_folder = None
            for folder in candidate_folders:
                if os.path.exists(folder):
                    found_folder = folder
                    break
                        
            if found_folder is None:
                print(f"[SKIP] Folder not found for {video_path}")
                skip_file +=1
                continue
            
            inspect_meta = data['metadata'].get('inspect', {})
            label_str = inspect_meta.get(self.task)
            if label_str is None:
                continue

            for ann in data.get('annotations', []):
                total_image +=1
                frame_num = ann['frame_number']
                timestamp = ann['timestamp']
                img_name = f"frame_{frame_num}_timestamp_{timestamp}.jpg"
                img_path = os.path.join(found_folder, img_name)

                if os.path.exists(img_path):
                    self.samples.append((img_path, label_str))
                    self.label_counter[label_str] += 1
                else:
                    # print(f"[MISSING] {img_path}")
                    missing_file +=1
        
        if self.describe :
            print("ë™ì˜ìƒ ìˆ˜ : ",total_video)  
            print("í”„ë ˆì„ ìˆ˜ : ",total_image)     
            print("ë¯¸ì”½ í”„ë ˆì„ ìˆ˜ : ",missing_file)
            print("íŒ¨ìŠ¤ íŒŒì¼ ìˆ˜ : ",pass_file)
            print("ìŠ¤í‚µ í´ë” ìˆ˜ : ",skip_file)
            print("\nğŸ“Š ë¼ë²¨ í†µê³„:")
            for label, count in self.label_counter.items():
                print(f"{label:10s}: {count}ê°œ")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label_str  = self.samples[idx]
        image = Image.open(img_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        label = self.label_encoder.encode(label_str)
        return image, label

def get_transform():
    return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor()
        ])


def get_dataloaders(batch_size=32, task='emotion', json_dir='data_mini_cat/CAT_labeled', img_root_dir='data_mini_cat/CAT_raw'):
    transform = get_transform()
    dataset = CatBehaviorDataset(transform = transform,json_dir=json_dir, img_root_dir=img_root_dir, task=task)

    # ì „ì²´ ë°ì´í„° ê°œìˆ˜
    total_size = len(dataset)
    if total_size == 0:
        raise ValueError("Dataset is empty. Check if the paths and label extraction are correct.")

    # í•™ìŠµ/ê²€ì¦ ë¹„ìœ¨ (ì˜ˆ: 80/20)
    train_size = int(0.8 * total_size)
    test_size = total_size - train_size

    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, test_loader