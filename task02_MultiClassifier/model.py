import torch
import torch.nn as nn
import torchvision.models as models
import timm

# timm.list_models(pretrained=True)             # ëª¨ë¸ ëª©ë¡ í™•ì¸

class MultiLabelImageClassifier(nn.Module):
    def __init__(self, num_actions, num_emotions, num_situations,
                 backbone_name='resnet18', pretrained=True):
        super(MultiLabelImageClassifier, self).__init__()

        # ë§ˆì§€ë§‰ FC ì œê±°í•˜ê³  feature extractorë§Œ ì¶”ì¶œ
        # self.shared_encoder = nn.Sequential(*list(base_model.children())[:-1])  # classification head ì œê±°
        # self.feature_dim = base_model.fc.in_features                            # ë§ˆì§€ë§‰ FC layerê°€ ì‚¬ìš©í•˜ë˜ ì…ë ¥ feature ìˆ˜ (512 or 2048, ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œ
        
        self.shared_encoder = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0)  # ğŸ”¸ classification head ì œê±°
        self.feature_dim = self.shared_encoder.num_features  # ğŸ”¸ ë§ˆì§€ë§‰ feature ì°¨ì› ì¶”ì¶œ

        # ë‹¤ì¤‘ ë¶„ë¥˜ê¸° head
        self.action_head = nn.Linear(self.feature_dim, num_actions)
        self.emotion_head = nn.Linear(self.feature_dim, num_emotions)
        self.situation_head = nn.Linear(self.feature_dim, num_situations)

    def forward(self, x):
        x = self.shared_encoder(x)          # (B, C, 1, 1)            ## backbone or shared_encoder
        x = x.view(x.size(0), -1)           # (B, C)

        # ê° head ì¶œë ¥
        action_logits = self.action_head(x)
        emotion_logits = self.emotion_head(x)
        situation_logits = self.situation_head(x)
        return action_logits, emotion_logits, situation_logits
    
    def get_model(self):
        return self
