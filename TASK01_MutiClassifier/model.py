import torch
import torch.nn as nn
import torchvision.models as models

class MultiLabelImageClassifier(nn.Module):
    def __init__(self, num_actions, num_emotions, num_situations,
                 backbone_name='resnet18', pretrained=True):
        super(MultiLabelImageClassifier, self).__init__()

        # ğŸ”¸ ì§€ì›í•˜ëŠ” backbone ëª©ë¡ (í™•ì¥ ê°€ëŠ¥)
        backbone_dict = {
            'resnet18': models.resnet18,
            'resnet34': models.resnet34,
            'resnet50': models.resnet50,
            'resnet101': models.resnet101,
            'resnet152': models.resnet152,
        }

        assert backbone_name in backbone_dict, f"Unsupported backbone: {backbone_name}"

        base_model = backbone_dict[backbone_name](pretrained=pretrained)

        # ğŸ”¸ ë§ˆì§€ë§‰ FC ì œê±°í•˜ê³  feature extractorë§Œ ì¶”ì¶œ
        self.shared_encoder = nn.Sequential(*list(base_model.children())[:-1])  # AdaptiveAvgPool2d í¬í•¨
        self.feature_dim = base_model.fc.in_features                            # ResNetì˜ ë§ˆì§€ë§‰ FC layerê°€ ì‚¬ìš©í•˜ë˜ ì…ë ¥ feature ìˆ˜ (512 or 2048, ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„)ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œ

        # ğŸ”¸ ë‹¤ì¤‘ ë¶„ë¥˜ê¸° head
        self.action_head = nn.Linear(self.feature_dim, num_actions)
        self.emotion_head = nn.Linear(self.feature_dim, num_emotions)
        self.situation_head = nn.Linear(self.feature_dim, num_situations)

    def forward(self, x):
        x = self.shared_encoder(x)          # (B, C, 1, 1)
        x = x.view(x.size(0), -1)           # (B, C)

        # ğŸ”¸ ê° head ì¶œë ¥
        action_logits = self.action_head(x)
        emotion_logits = self.emotion_head(x)
        situation_logits = self.situation_head(x)
        return action_logits, emotion_logits, situation_logits
    
    def get_model(self):
        return self
