import argparse
from video_utils import extract_frames
from vision_model import predict_emotion_behavior
from llm_generator import generate_narrative

def main(video_path):
    print("[1] ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
    frames = extract_frames(video_path)

    print(f"[2] ì´ {len(frames)}ê°œì˜ í”„ë ˆì„ ë¶„ì„ ì¤‘...")
    all_tags = set()
    for frame in frames:
        tags = predict_emotion_behavior(frame)
        all_tags.update(tags)

    print(f"[3] ì¶”ì¶œëœ íƒœê·¸: {list(all_tags)}")
    print("[4] LLMìœ¼ë¡œ ìì—°ì–´ ìƒì„± ì¤‘...")
    narrative = generate_narrative(list(all_tags))

    print("\nğŸ“£ ë°˜ë ¤ë™ë¬¼ì˜ ë§:")
    print(narrative)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë°˜ë ¤ë™ë¬¼ í–‰ë™ ë¶„ì„ CLI")
    parser.add_argument("video", help="ë¶„ì„í•  ì˜ìƒ íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()

    main(args.video)
